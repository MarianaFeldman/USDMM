{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import cv2\n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1,0],[1,1,1],[0,1,0]]) # Janela EM cruz\n",
    "W_size = W.shape[0]\n",
    "inc = int(round(W_size/2-0.1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for img in range(1,15):\n",
    "    s = str(img)\n",
    "    s = s.zfill(2)\n",
    "    img_in = cv2.imread('./X/img'+s+'.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    img_out = cv2.imread(\"./y/img\"+s+\".jpg\", cv2.IMREAD_GRAYSCALE) # bordas\n",
    "    #y = cv2.imread(\"./data_out_sp/img\"+s+\".jpg\", cv2.IMREAD_GRAYSCALE) # sal-pimenta\n",
    "    (T, img_in) = cv2.threshold(img_in, 100, 255, cv2.THRESH_BINARY)\n",
    "    (T, img_out) = cv2.threshold(img_out, 100, 255, cv2.THRESH_BINARY)\n",
    "    if img > 6:\n",
    "        img_in[(img_in==0)]=1\n",
    "        img_out[(img_out==0)]=1\n",
    "        \n",
    "        img_in[(img_in==255)]=0\n",
    "        img_out[(img_out==255)]=0\n",
    "        \n",
    "    else:\n",
    "        img_in[(img_in==255)]=1\n",
    "        img_out[(img_out==255)]=1\n",
    "    \n",
    "    \n",
    "    img_in = img_in.astype(int)\n",
    "    img_out = img_out.astype(int)\n",
    "    \n",
    "    img_inl = np.c_[np.zeros([img_in.shape[0],inc], dtype=int),img_in, np.zeros([img_in.shape[0],inc], dtype=int)]\n",
    "    img_inl = np.r_[np.zeros([inc,img_inl.shape[1]], dtype=int),img_inl, np.zeros([inc,img_inl.shape[1]], dtype=int)]\n",
    "    \n",
    "    for i in range(img_in.shape[0]):\n",
    "        for j in range(img_in.shape[1]):\n",
    "\n",
    "            px = []\n",
    "            for k in range(W.shape[0]):\n",
    "                for r in range(W.shape[1]):\n",
    "                    if W[k,r]==1:\n",
    "                        px.append(img_inl[i-inc+1+k,j-inc+1+r])\n",
    "        \n",
    "            X.append(px)\n",
    "            y.append(img_out[i,j])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 0 to -1 to the neural network\n",
    "X[X==0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(1,-1)\n",
    "\n",
    "X = np.transpose(X)\n",
    "print(f\"X: {X.shape}, y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X: {X.shape}, y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [5,32,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims, fixed_first_layer = True):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for l in range(1, L):\n",
    "        if (l==1)and(fixed_first_layer):\n",
    "            parameters['W' + str(l)] = np.array([list(i) \n",
    "                                                 for i in itertools.product([-1, 1]\n",
    "                                                 , repeat=layer_dims[l - 1])])\n",
    "            parameters['b' + str(l)] = np.array([-4]*layer_dims[l]).reshape(layer_dims[l],1)\n",
    "        else:\n",
    "            parameters['W' + str(l)] = np.random.randn(layer_dims[l],\n",
    "                                                   layer_dims[l - 1]) * 0.1\n",
    "            parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "        assert(parameters['W' + str(l)].shape ==\n",
    "               (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "\n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def L_activation_forward(A_prev, W, b):\n",
    "    Z, linear_cache = L_forward(A_prev, W, b)\n",
    "    A, activation_cache = sigmoid(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    A = X\n",
    "    caches = []\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "\n",
    "        A, cache = L_activation_forward(\n",
    "            A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)])\n",
    "        caches.append(cache)\n",
    "\n",
    "    return A, caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -(np.sum(Y * np.log(AL) + (1.0 - Y) * np.log(1.0 - AL))) / m # Logloss error\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.dot(dZ, A_prev.T) / m # delta W = gradient * neurons_inputs\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m # delta bias = sigmoid derivative median\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "    \n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s) # gradient = sigmoid derivative * logloss derivative\n",
    "\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_activation_backward(dA, cache):\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    dZ = sigmoid_backward(dA, activation_cache)\n",
    "    dA_prev, dW, db = L_backward(dZ, linear_cache)\n",
    "\n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    Y = Y.reshape(AL.shape)\n",
    "\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # logloss derivative\n",
    "\n",
    "    current_cache = caches[L - 1]\n",
    "    dA_prev_temp, dW_temp, db_temp = L_activation_backward(dAL, current_cache)\n",
    "    grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
    "    grads[\"dW\" + str(L)] = dW_temp\n",
    "    grads[\"db\" + str(L)] = db_temp\n",
    "\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = L_activation_backward(\n",
    "            grads[\"dA\" + str(l + 1)], current_cache)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate, fixed_first_layer):\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        # W_new = W_old - learning_rate * gradient_W\n",
    "        # b_new = b_old - learning_rate * gradient_b\n",
    "        \n",
    "        if fixed_first_layer and l==0:\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] \n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] \n",
    "        else:\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - \\\n",
    "                learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - \\\n",
    "                learning_rate * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_train(X, Y, layers_dims, learning_rate=0.1, num_iterations = 20000\n",
    "                   , print_cost = True, fixed_first_layer = True, ini_param = False):\n",
    "    np.random.seed(1)\n",
    "    costs = [] # keep track of cost\n",
    "\n",
    "    # Parameters initialization.\n",
    "    if ini_param:\n",
    "        with open(\"parameters_v9.pkl\",\"rb\") as r:\n",
    "            parameters = pickle.load(r)\n",
    "    else:\n",
    "        parameters = initialize_parameters(layers_dims, fixed_first_layer)\n",
    "\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters) # Calculate the output of the network -- forward propagation\n",
    "        cost = compute_cost(AL, Y) # Calculate the Logloss error\n",
    "        grads = L_model_backward(AL, Y, caches) # Calculate the Gradient\n",
    "        parameters = update_parameters(parameters, grads, learning_rate, fixed_first_layer)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            learning_rate = learning_rate / 2 # After 2.000 iterarions, divide learning_rate by 2\n",
    "        if i % 2000 == 0:\n",
    "            learning_rate = learning_rate / 2 # After 2.000 iterarions, divide learning_rate by 2\n",
    "\n",
    "        if print_cost and i % 10 == 0 or i == num_iterations - 1:\n",
    "            print(f\"Cost after iteration {i}: {np.squeeze(cost)}\")\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "\n",
    "    return parameters, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [5, 32, 1] # 5 inputs / 1 hidden layer with 2^5 = 32 neurons / 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters, costs = nn_model_train(\n",
    "    X, y, layers_dims, learning_rate = 0.2, num_iterations=500, print_cost=True, fixed_first_layer = True, ini_param =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"parameters_v10.pkl\",\"wb\")\n",
    "pickle.dump(parameters,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1, m))\n",
    "\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0, i] > 0.5:\n",
    "            p[0, i] = 1\n",
    "        else:\n",
    "            p[0, i] = 0\n",
    "    print(\"Accuracy: \" + str(np.sum((p == y)/m)))\n",
    "\n",
    "    return p\n",
    "\n",
    "def apply(X, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1, m))\n",
    "\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0, i] > 0.57:\n",
    "            p[0, i] = 255\n",
    "        else:\n",
    "            p[0, i] = 0\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(X, y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(1,17):\n",
    "    s = str(img)\n",
    "    s = s.zfill(2)\n",
    "    x = cv2.imread('./X/img'+s+'.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    #cv2.imshow('image',x)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    (T, x) = cv2.threshold(x, 100, 255, cv2.THRESH_BINARY)\n",
    "    x[(x==255)]=1\n",
    "    \n",
    "    x = x.astype(int)\n",
    "    \n",
    "    Xl = np.c_[np.zeros([x.shape[0],inc], dtype=int),x, np.zeros([x.shape[0],inc], dtype=int)]\n",
    "    Xl = np.r_[np.zeros([inc,Xl.shape[1]], dtype=int),Xl, np.zeros([inc,Xl.shape[1]], dtype=int)]\n",
    "    \n",
    "    z = np.zeros(x.shape, dtype=int)\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        row = []\n",
    "        for j in range(x.shape[1]):\n",
    "\n",
    "            px = []\n",
    "            for k in range(W.shape[0]):\n",
    "                for r in range(W.shape[1]):\n",
    "                    if W[k,r]==1:\n",
    "                        px.append(Xl[i-inc+1+k,j-inc+1+r])\n",
    "            row.append(px)\n",
    "            \n",
    "        row = np.transpose(np.array(row))\n",
    "        result = apply(row,parameters)\n",
    "        \n",
    "                        \n",
    "        z[i,:] = result\n",
    "    \n",
    "    cv2.imwrite('./data_out/img'+s+'.jpg', z) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
